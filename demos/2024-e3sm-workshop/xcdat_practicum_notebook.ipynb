{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Analysis and Visualization of E3SM Data using nco and xCDAT\n",
    "\n",
    "E3SM Tutorial Workshop 2024\n",
    "\n",
    "05/07/2024\n",
    "\n",
    "Authors: [Tom Vo](https://github.com/tomvothecoder) and [Stephen Po-Chedley](https://github.com/pochedls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This exercise notebook will walkthrough using regridding E3SM data to a\n",
    "rectilinear grid using `ncremap`, then performing analysis and visualization using xCDAT.\n",
    "\n",
    "### Sections\n",
    "\n",
    "1. Prerequisite: Set up the E3SM Unified Environment v1.10.0 Python Kernel\n",
    "2. Setup Code\n",
    "3. Use NCO to regrid E3SM data to a rectilinear grid\n",
    "4. I/O\n",
    "5. Regridding\n",
    "6. Spatial Averaging\n",
    "7. Temporal Computations\n",
    "8. General Dataset Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Set up the E3SM Unified Environment Kernel\n",
    "\n",
    "_Skip this section if you've already done it_\n",
    "\n",
    "1. Run the cell below to add the E3SM Unified Environment v1.10.0 kernel to Jupyter Hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Source https://docs.nersc.gov/services/jupyter/how-to-guides/#how-to-use-a-conda-environment-as-a-python-kernel\n",
    "# Activate the E3SM Unified Environment\n",
    "source /global/common/software/e3sm/anaconda_envs/load_latest_e3sm_unified_pm-cpu.sh\n",
    "\n",
    "# Add the E3SM Unified Environment kernel to Jupyter Hub\n",
    "python -m ipykernel install \\\n",
    "--user --name e3sm_unified_1.10.0 --display-name e3sm_unified_1.10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. Refresh this page.\n",
    "4. Select the kernel for this notebook by clicking the current kernel in the top-right\n",
    "   (where it says NERSC Python in the screenshot).\n",
    "\n",
    "   <img src=\"kernel-instructions-1.png\" width=500px/>\n",
    "\n",
    "5. Select `e3sm_unified.1.10.0` from the list of environments.\n",
    "\n",
    "   <img src=\"kernel-instructions-2.png\" width=500px/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from xarray.coding.calendar_ops import _datetime_to_decimal_year as dt2decimal\n",
    "import xcdat as xc\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NCO to regrid E3SM data to a rectilinear grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now call ncremap to regrid the file to a 0.5 x 0.5 degree grid\n",
    "\n",
    "Typically a user would call this command directly from the shell or write a batch script to run ncremap. Here we use the bash decorator in Jupyter to run `ncremap` on a directory of files (using a wildcard to filter for `.h0` files, which include monthly output weâ€™d like to analyze). We will then move the remapped files to a `remapped/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# create output directory\n",
    "mkdir -p remapped\n",
    "# source e3sm-unified environment\n",
    "source /global/common/software/e3sm/anaconda_envs/load_latest_e3sm_unified_pm-cpu.sh\n",
    "# do regridding\n",
    "# format: ncremap -m REMAPFILE.nc -t 1 -v VAR_OF_INTEREST /PATH/TO/DATA/*nc\n",
    "# Subsetting files for \"h0\", which is the monthly history field.\n",
    "ncremap -m /global/cfs/cdirs/e3sm/diagnostics/maps/map_ne30pg2_to_cmip6_180x360_aave.20200201.nc -t 1 -v TREFHT /global/cfs/cdirs/e3sm/www/Tutorials/2024/simulations/extendedOutput.v3.LR.historical_0101/archive/atm/hist/extendedOutput.v3.LR.historical_0101.eam.h0.*nc >/dev/null 2>&1\n",
    "# move output to remapped directory\n",
    "mv extendedOutput.v3.LR.historical_0101.eam.h0.*nc remapped/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's load in the regridded data and use xcdat to perform additional calculations on the 0.5 x 0.5 degree grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Use `xc.open_mfdataset()` to open all the remapped netcdf files in a single `xr.Dataset` object. With `xcdat`, you can specify the directory `remapped` and xcdat will read in all netcdf files as one `xr.dataset` object. You could also use a wildcard with xarray (`ds = xr.open_mfdataset('remapped/*.ncâ€™)`). `open_mfdataset` is essentially the same operation in both Xarray and xCDAT, but `xcdat` will add missing bounds and handles some additional time axes. \n",
    "\n",
    "We will be analyzing a few years of temperature (`TREFHT`) data from E3SM v3.\n",
    "\n",
    "- Documentation: https://xcdat.readthedocs.io/en/stable/generated/xcdat.open_mfdataset.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. When ready, click on the three dots below for the solution.\n",
    "ds = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xc.open_mfdataset(\"remapped\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but checkout the time coordinate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.time.values[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monthly time coordinates begin in 2/2000, even though our first file is for 1/2000. This is because E3SM saves out monthly history at midnight at the end of the month. xCDAT can handle this by centering the time coordinates between the monthly time bounds (using `center_times=True`):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Use `xc.open_mfdataset()` again, but make sure to center the time coordinates.\n",
    "\n",
    "- Documentation: https://xcdat.readthedocs.io/en/latest/generated/xcdat.open_mfdataset.html#xcdat.open_mfdataset\n",
    "- Hint: Use the `center_times` arg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. When ready, click on the three dots below for the solution.\n",
    "ds = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xc.open_mfdataset(\"remapped\", center_times=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regridding with xCDAT\n",
    "\n",
    "We often want to regrid a dataset to a new grid to facilitate data analysis or comparisons with other datasets. The current dataset is at 0.5 x 0.5<sup>o</sup> resolution, so we'll start be remapping it to a 4 x 4<sup>o</sup> grid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we specify the target grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create target axes\n",
    "nlat = xc.create_axis(\n",
    "    \"lat\", np.arange(-88, 90, 4), attrs={\"units\": \"degrees_north\", \"axis\": \"Y\"}\n",
    ")\n",
    "nlon = xc.create_axis(\n",
    "    \"lon\", np.arange(2, 360, 4), attrs={\"units\": \"degrees_east\", \"axis\": \"X\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Create the target grid using the target axes and bounds.\n",
    "\n",
    "- Documentation: https://xcdat.readthedocs.io/en/latest/generated/xcdat.create_grid.html#xcdat.create_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. When ready, click on the three dots below for the solution.\n",
    "ngrid = xc.create_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ngrid = xc.create_grid(x=nlon, y=nlat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the xESMF regridder\n",
    "\n",
    "Here we're using bilinear regridding, but other methods may be appropriate (e.g., you may want to use \"conservative_normed\" for fields that should be conserved globally).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Regrid \"TREFHT\" with the `ngrid` created above using `xesmf` and `bilinear`.\n",
    "\n",
    "- API Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.regridder.horizontal.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds_xesmf = ds.regridder.horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_xesmf = ds.regridder.horizontal(\"TREFHT\", ngrid, tool=\"xesmf\", method=\"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results (for the first timestep)\n",
    "\n",
    "Now we just plot the results for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_proj = ccrs.Robinson()\n",
    "\n",
    "# plot original data (first time step)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1, projection=map_proj)\n",
    "p = ds.TREFHT[0].plot(\n",
    "    transform=ccrs.PlateCarree(),  # the data's projection\n",
    "    subplot_kws={\"projection\": map_proj},\n",
    "    cbar_kwargs={\"orientation\": \"horizontal\"},\n",
    "    cmap=plt.cm.RdBu_r,\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "plt.title(\"Original\")\n",
    "\n",
    "# plot the remapped data (first time step)\n",
    "plt.subplot(1, 2, 2, projection=map_proj)\n",
    "p = ds_xesmf.TREFHT[0].plot(\n",
    "    transform=ccrs.PlateCarree(),  # the data's projection\n",
    "    subplot_kws={\"projection\": map_proj},\n",
    "    cbar_kwargs={\"orientation\": \"horizontal\"},\n",
    "    cmap=plt.cm.RdBu_r,\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "plt.title(\"xESMF 4$^{\\circ}$ x 4$^{\\circ}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical Regridding\n",
    "\n",
    "xcdat can also regrid in the vertical. Here we'll grab some 3D temperature data and regrid it in the vertical. First, we need to remap some 3-dimensional data to a rectilinear grid (like we did for the surface air temperature data, `TREFHT`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# source e3sm-unified environment\n",
    "source /global/common/software/e3sm/anaconda_envs/load_latest_e3sm_unified_pm-cpu.sh\n",
    "# remap (we are only remapping one file and specifying the output location)\n",
    "ncremap -m /global/cfs/cdirs/e3sm/diagnostics/maps/map_ne30pg2_to_cmip6_180x360_aave.20200201.nc -t 1 -v T /global/cfs/cdirs/e3sm/www/Tutorials/2024/simulations/extendedOutput.v3.LR.historical_0101/archive/atm/hist/extendedOutput.v3.LR.historical_0101.eam.h0.2000-01.nc T_extendedOutput.v3.LR.historical_0101.eam.h0.2000-01.nc >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify file we just regridded\n",
    "fn = \"T_extendedOutput.v3.LR.historical_0101.eam.h0.2000-01.nc\"\n",
    "\n",
    "# load regridded data\n",
    "ds3d = xc.open_dataset(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will do the vertical remapping...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first construct the 3D pressure field\n",
    "pressure = ds3d[\"hyam\"] * 1000.0 + ds3d[\"hybm\"] * ds3d[\"PS\"]\n",
    "\n",
    "# next, construct the target pressure axis\n",
    "target_plevs = [\n",
    "    100000,\n",
    "    92500,\n",
    "    85000,\n",
    "    75000,\n",
    "    70000,\n",
    "    60000,\n",
    "    50000,\n",
    "    40000,\n",
    "    30000,\n",
    "    25000,\n",
    "    20000,\n",
    "    15000,\n",
    "    10000,\n",
    "    7000,\n",
    "    5000,\n",
    "    3000,\n",
    "    1000,\n",
    "    500,\n",
    "    300,\n",
    "    100,\n",
    "]\n",
    "nplev = xc.create_grid(z=xc.create_axis(\"lev\", target_plevs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Regrid the `\"T\"` variable using `nplev` as the output grid, `\"log\"` method, and `pressure` as the target data.\n",
    "\n",
    "- Example Documentation: https://xcdat.readthedocs.io/en/stable/examples/regridding-vertical.html#4:-Remap-cloud-fraction-from-model-hybrid-coordinate-to-pressure-levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "dsvr = ds3d.regridder.vertical(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsvr = ds3d.regridder.vertical(\"T\", nplev, method=\"log\", target_data=pressure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot result\n",
    "dsvr_zonal = dsvr.spatial.average(\"T\", axis=[\"X\"]).squeeze()\n",
    "dsvr_zonal.T.plot(cmap=plt.cm.RdBu_r)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Averaging with xCDAT\n",
    "\n",
    "Area-weighted spatial averaging is a common technique to reduce dimensionality in geospatial datasets. xCDAT can perform this calculation over full domains or regions of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Calculate the spatial average of \"TREFHT\" and store the results in a Python variable.\n",
    "\n",
    "- API Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.spatial.average.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. When ready, click on the three dots below for the solution.\n",
    "ds_global = ds.spatial.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_global = ds.spatial.average(\"TREFHT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's plot the results.\n",
    "\n",
    "Note that the spatial averager returns a dataset object so we still need to specify \"TREFHT\" to plot the dataarray.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtime = dt2decimal(ds_global.time)  # decimal time\n",
    "plt.plot(dtime, ds_global[\"TREFHT\"].values)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Global Mean Temperature [K]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we did not specify any constraints. So xCDAT calculated the domain (global) average. Users can also specify their own bounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Calculate the the average surface temperature (`\"TREFHT\"`) in the NiÃ±o 3.4 region.\n",
    "\n",
    "- API Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.spatial.average.html\n",
    "- Hint: Pass latitude bounds of (-5, 5) and longitude bounds of (190, 240) and keep the weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds_nino34 = ds_xesmf.spatial.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_nino34 = ds_xesmf.spatial.average(\n",
    "    \"TREFHT\", lat_bounds=(-5, 5), lon_bounds=(190, 240), keep_weights=True\n",
    ").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we specified `keep_weights=True`. The weights provide full spatial weighting for grid cells entirely within the NiÃ±o 3.4 region. If a grid cell is partially in the NiÃ±o 3.4 region, it received partial weight (note we use the 4 x 4 degree grid in this example to show the partial weights and to speed up plotting). Note that you can also supply your own weights (but you can't automatically subset with `lat_bounds` and `lon_bounds` if you supply your own weights).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show the nino 3.4 time series\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(dtime, ds_nino34[\"TREFHT\"].values)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Surface Temperature [K]\")\n",
    "plt.title(\"NiÃ±o 3.4 time series\")\n",
    "\n",
    "# show the weights\n",
    "map_proj = ccrs.PlateCarree(central_longitude=180)\n",
    "ax = plt.subplot(1, 2, 2, projection=map_proj)\n",
    "plt.pcolor(\n",
    "    ds_nino34.lon,\n",
    "    ds_nino34.lat,\n",
    "    ds_nino34.lat_lon_wts.T,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=plt.cm.GnBu,\n",
    ")\n",
    "ax.set_extent([120, 300, -30, 30], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "plt.title(\"Nino 3.4 Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Computations with xCDAT\n",
    "\n",
    "In the examples below, we will performing temporal computations on the `xarray.Dataset` object using xCDAT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual cycle\n",
    "\n",
    "In the global mean time series above, there are large seasonal swings in global temperature. Here we compute the seasonal mean climatology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Calculate the seasonal mean climatology for the `\"TREFHT\"` variable.\n",
    "\n",
    "- API Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.temporal.climatology.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds_clim = ds.temporal.climatology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the climatology\n",
    "ds_clim = ds.temporal.climatology(\"TREFHT\", freq=\"season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we plot the season means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_proj = ccrs.Robinson()\n",
    "titles = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1, projection=map_proj)\n",
    "    p = ds_clim.TREFHT[i].plot(\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        subplot_kws={\"projection\": map_proj},\n",
    "        cbar_kwargs={\"orientation\": \"horizontal\"},\n",
    "        cmap=plt.cm.RdBu_r,\n",
    "        vmin=220,\n",
    "        vmax=310,\n",
    "    )\n",
    "    ax = plt.gca()\n",
    "    ax.coastlines()\n",
    "    plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Departures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "It can also be useful to show the departures from the climatological average.\n",
    "\n",
    "Calculate the seasonal mean climatology for the `\"TREFHT\"` variable. In this case, `xcdat` will operate on the global mean time series we calculated above. Note that you can set the climatological reference period (e.g., with `reference_period=(\"1950-01-01\", \"1999-12-31\")` for historical era departures).\n",
    "\n",
    "- API Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.temporal.departures.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds_global_anomaly = ds_global.temporal.departures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_global_anomaly = ds_global.temporal.departures(\n",
    "    \"TREFHT\", freq=\"month\", reference_period=(\"2000-01-01\", \"2009-12-31\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot the departures from the climatological average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(dtime, ds_global_anomaly.TREFHT.values)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Global Mean Surface Temperature Anomaly [K]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group averages\n",
    "\n",
    "`xcdat` also allows you to calculate group averages (e.g., annual or seasonal mean from monthly data or monthly mean from daily data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Calculate the annual mean from anomaly time series.\n",
    "\n",
    "- API Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.temporal.group_averages.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds_global_anomaly_annual = ds_global_anomaly.temporal.group_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute annual mean from anomaly time series\n",
    "ds_global_anomaly_annual = ds_global_anomaly.temporal.group_average(\n",
    "    \"TREFHT\", freq=\"year\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "dtime_annual = dt2decimal(ds_global_anomaly_annual.time) + 0.5\n",
    "plt.plot(\n",
    "    dtime, ds_global_anomaly.TREFHT.values, label=\"Monthly departure\", color=\"gray\"\n",
    ")\n",
    "plt.plot(\n",
    "    dtime_annual,\n",
    "    ds_global_anomaly_annual.TREFHT.values,\n",
    "    color=\"k\",\n",
    "    linestyle=\"\",\n",
    "    marker=\"_\",\n",
    "    label=\"Annual Mean\",\n",
    ")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Global Mean Surface Temperature [K]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Dataset Utilities\n",
    "\n",
    "xCDAT includes various utilities for data manipulation, including\n",
    "reorientation of the longitude axis, centering of time coordinates using time bounds, and adding and getting bounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorient the longitude axis\n",
    "\n",
    "Longitude can be represented from 0 to 360 E or as 180 W to 180 E. xcdat allows you to convert between these axes systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Use `xc.swap_lon_axis` to swap the longitude axis from (0, 360) to (-180, 180) and view\n",
    "the new longitude axis.\n",
    "\n",
    "- Documentation: https://xcdat.readthedocs.io/en/stable/generated/xcdat.swap_lon_axis.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds2 =\n",
    "\n",
    "ds2.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds2 = xc.swap_lon_axis(ds, to=(-180, 180))\n",
    "\n",
    "ds2.lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing bounds\n",
    "\n",
    "Bounds are critical to many `xcdat` operations. For example, they are used in determining the weights in spatial or temporal averages and in regridding operations. `add_missing_bounds()` will attempt to produce bounds if they do not exist in the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We are dropping the existing bounds to demonstrate adding bounds.\n",
    "ds4 = ds.drop_vars(\"time_bnds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ds4.bounds.get_bounds(\"T\")\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» Your turn:\n",
    "\n",
    "Add the missing time bounds using `.bounds.add_missing_bounds()`.\n",
    "\n",
    "- Documentation: https://xcdat.readthedocs.io/en/stable/generated/xarray.Dataset.bounds.add_missing_bounds.html\n",
    "- Hint: Use the `axes` arg and pass a list containing a single string, `\"T\"` for time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code here. When ready, click on the three dots below for the solution.\n",
    "ds5 = ds4.bounds.add_missing_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds5 = ds4.bounds.add_missing_bounds(axes=[\"T\"])\n",
    "ds5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability with UXarray\n",
    "\n",
    "UXarray provides Xarray-styled functionality for working with unstructured grids built around the UGRID conventions. Since UXarray's `ux.UxDataset` and `ux.UxDataArray` extend the `xr.Dataset` and `xr.DataArray` classes, _most_ xCDAT APIs are interoperable with UXarray objects.\n",
    "\n",
    "- The exception is xCDAT's [spatial averager](https://xcdat.readthedocs.io/en/latest/generated/xarray.Dataset.spatial.average.html), which requires data on rectilinear grids. The data must first be remapped from unstructured to rectilinear grid using another tool like `nco` (`ncremap`).\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Congratulations on completing the xCDAT Practicum notebook for 2024 E3SM Tutorial\n",
    "Workshop! If you haven't already, feel free to jump over to the `uxarray_practicum_notebook.ipynb`\n",
    "to work with `uxarray`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e3sm_unified_1.10.0",
   "language": "python",
   "name": "e3sm_unified_1.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
